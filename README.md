# Linear Regression

Linear regression is a large topic with rich history within machine learning. As this course progresses, we will dive more deeply into the mathematical foundations of multiple linear regression, with particular emphasis on Singular Value Decomposition and its connections to Principle Component Analysis. These foundations fall mostly outside the scope of this lesson, however.

## Objectives

You should be able to:

1. Provide a summary of linear regression basics. In particular, you should be able to describe goals, use cases, and parameters used in:
    - Simple Linear Regression
    - Multiple Linear Regression
1. Apply scientific computing tools to build linear regression models
1. Use statistical analysis and visualization tools to check the following model assumptions
    - Linearity
    - Residual errors are normally distributed with mean 0
    - Homoscedasticity of Residuals
    - Multivariate Normality
    - Little multicollinearity
1. Evaluate model with appropriate statistical analyses including:
    - Mean square error
    - R<sup>2</sup> statistic

## Resources

- Covered during this lesson:
    - [Slide Deck](https://docs.google.com/presentation/d/1eT_HY8RoRo7zLmAqepz9JvVFaN-GZHVeGzPjlk9LNWA/edit?usp=sharing)
    - [Notebook](<./notebooks/Multiple Linear Regression.ipynb>)
- Mathematical Background:
    - [Video Overview](https://www.youtube.com/watch?v=EDPCsD6BzWE)
    - [In-depth reading (pp. 134)](http://databookuw.com/databook.pdf)
- Data
    - You can find the data used in the notebook [here](https://www.kaggle.com/akdagmelih/multiplelinear-regression-fish-weight-estimation/data)